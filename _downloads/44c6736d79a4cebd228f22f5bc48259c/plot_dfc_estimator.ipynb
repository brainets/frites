{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Estimate the Dynamic Functional Connectivity\n\nThis tutorial illustrates how to compute the Dynamic Functional Connectivity\n(DFC). In particular, we will adress :\n\n* How to estimate the DFC at the single trial-level inside a unique time window\n* How to estimate the DFC on sliding windows\n* How to use different estimators (mutual-information, correlation and distance\n  correlation)\n* What are the strengths and weaknesses of each estimator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport xarray as xr\n\nfrom frites.estimator import (GCMIEstimator, CorrEstimator, DcorrEstimator)\nfrom frites.conn import conn_dfc, define_windows\nfrom frites import set_mpl_style\n\nimport matplotlib.pyplot as plt\nset_mpl_style()\n\n# for reproducibility\nnp.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data simulation\n\nIn this first section, we generate simulated data. We first use random data\ncoming from several brain regions and then we introduce some correlations\nbetween the first two brain regions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_trials = 100\nn_roi = 3\nn_times = 250\ntrials = np.arange(n_trials)\nroi = [f\"r{n_r}\" for n_r in range(n_roi)]\ntimes = np.arange(n_times) / 64.\nx = np.random.uniform(-1, 1, (n_trials, n_roi, n_times))\n\n# positive correlation between samples [40, 60]\nx[:, 0, 40:60] += .4 * x[:, 1, 40:60]\n# negative correlation between samples [90, 110]\nx[:, 0, 90:110] -= .4 * x[:, 1, 90:110]\n# non-linear but monotone relationship between samples [140, 160]\nx[:, 0, 140:160] += .4 * x[:, 1, 140:160] ** 3\n# non-linear and non-monotone relationship between samples [190, 210]\nx[:, 0, 190:210] += x[:, 1, 190:210] ** 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To summarize :\n\n        1. Electrophysiological data is a 3D array of shape\n           (100 trials, 3 brain regions, 250 time points)\n        2. Brain regions 0 and 1 are positively correlated between samples\n           [40, 60]\n        3. Brain regions 0 and 1 are negatively correlated between samples\n           [90, 110]\n        3. Brain regions 0 and 1 are positively correlated between samples\n           [140, 160] with a monotone but non-linear relationship\n        4. Brain regions 0 and 1 are positively correlated between samples\n           [190, 210] with a non-monotone and non-linear relationship</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# dataarray transformation\nx = xr.DataArray(x, dims=('trials', 'space', 'times'),\n                 coords=(trials, roi, times))\nprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computes the DFC in a single temporal window\n\nIn the section we compute the DFC inside a single time-window. Actually, the\nDFC is going to be computed across the entire time-series\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# compute the dfc\ndfc = conn_dfc(x, times='times', roi='space')\n\nprint(dfc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computes the DFC on sliding windows\n\nIn this section, we are going to define sliding windows and then compute the\nDFC inside each one of them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "slwin_len = .5    # windows of length 500ms\nslwin_step = .02  # 20ms step between each window (or 480ms overlap)\n\n# define the sliding windows\nsl_win = define_windows(times, slwin_len=slwin_len, slwin_step=slwin_step)[0]\nprint(sl_win)\n\n# compute the DFC on sliding windows\ndfc = conn_dfc(x, times='times', roi='space', win_sample=sl_win)\n\n# takes the mean over trials\ndfc_m = dfc.mean('trials').squeeze()\n\n# plot the mean over trials\ndfc_m.plot.line(x='times', hue='roi')\nplt.title(dfc.name), plt.ylabel('DFC')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of several estimators\n\nBy default, the `conn_dfc` function uses the Gaussian-Copula\nMutual-Information (GCMI) estimator. However, the `conn_dfc` function allows\nto provide other estimators as soon as it is made for computing information\nbetween two continuous variables (`mi_type='cc'`). In this final section, we\nare going to use different estimators, especially the standard correlation\nand the distance correlation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est_mi = GCMIEstimator('cc', copnorm=None, biascorrect=False)\nest_corr = CorrEstimator()\nest_dcorr = DcorrEstimator()\n\nfig, axs = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(6, 12))\n\nfor n_e, est in enumerate([est_mi, est_corr, est_dcorr]):\n    # compute the dfc\n    dfc = conn_dfc(x, times='times', roi='space', win_sample=sl_win,\n                   estimator=est)\n\n    # take the mean across trials\n    dfc_m = dfc.mean('trials')\n\n    # plot the result\n    plt.sca(axs[n_e])\n    dfc_m.plot.line(x='times', hue='roi', ax=plt.gca())\n    plt.title(dfc.name)\n    plt.ylabel('DFC')\n    if n_e != 2: plt.xlabel('')\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To summarize :\n\n        1. GCMI estimators offers a great sensibility. However, the\n           mutual-information is unsigned and therefore, negative\n           correlations are captured as positive information (cf. second\n           bump). In addition, non-monotone relations are not well captured\n        2. On the other hand, the correlation clearly extract both positive\n           and negative correlations however, non-monotone relationships are\n           missed. Finally, the correlation is probably not as sensible as\n           the GCMI\n        3. Finally, the distance correlation captures all relations but as\n           the GCMI, it is an unsigned measure, missing negative\n           correlations. It is the most powerful estimator however, it is\n           also slower to compute.</p></div>\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}