{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTrial-resampling: correcting for unbalanced designs\n===================================================\n\nThis example illustrates how to correct information estimation in case of\nunbalanced designs (i.e. when the number of epochs or trials is very different\nbetween conditions).\n\nThe technique of trial-resampling consist in randomly taking an equal number of\ntrials per condition, estimating the effect size and then repeating this\nprocedure for a more reliable estimation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\n\nfrom frites.estimator import GCMIEstimator, ResamplingEstimator, DcorrEstimator\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data creation\n-------------\n\nThis first section creates the data using random points drawn from gaussian\ndistributions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_variables = 1000  # number of random variables\nn_epochs = 500      # total number of epochs\nprop = 5            # proportion (in percent) of epochs in the first condition\n\n# proportion of trials\nn_prop = int(np.round(prop * n_epochs / 100))\n\n# create continuous variables\nx_1 = np.random.normal(loc=1., size=(n_variables, 1, n_prop))\nx_2 = np.random.normal(loc=2., size=(n_variables, 1, n_epochs - n_prop))\nx = np.concatenate((x_1, x_2), axis=-1)\ny_c = np.r_[np.random.normal(size=(n_prop,)),\n            np.random.normal(size=(n_epochs - n_prop,))]\n\n# create discret variable\ny_d = np.array([0] * n_prop + [1] * (n_epochs - n_prop))\n\nprint(f\"Smaller dataset : {x_1.shape}\")\nprint(f\"Larger dataset : {x_2.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Information shared between a continuous and a discret variable\n--------------------------------------------------------------\n\nIn this second section, we define an estimator for computing the information\nshared between a continuous and a discret variable. In a second step, we are\ngoing to wrap this estimator with a trial-resampling estimator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# mutual information uncorrected estimator\nest = GCMIEstimator(mi_type='cd', biascorrect=False)\nmi_1 = est.estimate(x, y_d).squeeze()\n\n# mutual information corrected estimator (with trial-resampling)\nest_r = ResamplingEstimator(est, n_resampling=100)\nmi_2 = est_r.estimate(x, y_d).squeeze()\n\ndf = pd.DataFrame({\n    'MI': np.r_[mi_1, mi_2],\n    'Estimator': ['Uncorrected'] * len(mi_1) + ['Corrected'] * len(mi_2)\n})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>As shown below, the effect size for the corrected estimator is slightly\n    over the non-corrected one.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.displot(df, x='MI', hue='Estimator', kde=True, height=7)\nplt.title(\"Information shared between a continuous and a discrete variable\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Information shared between two continuous variables\n---------------------------------------------------\n\nIn this last section, we define an estimator for computing the information\nshared between two continuous variables. Similarly to above, we are then\ngoing to wrap this estimator with a trial-resampling estimator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# distance correlation uncorrected estimator\nest = DcorrEstimator()\nmi_1 = est.estimate(x, y_c, z=y_d).squeeze()\n\n# distance correlation corrected estimator (with trial-resampling)\nest_r = ResamplingEstimator(est, n_resampling=20)\nmi_2 = est_r.estimate(x, y_c, z=y_d).squeeze()\n\ndf = pd.DataFrame({\n    'MI': np.r_[mi_1, mi_2],\n    'Estimator': ['Uncorrected'] * len(mi_1) + ['Corrected'] * len(mi_2)\n})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>As shown below, the effect size for the corrected estimator is slightly\n    over the non-corrected one.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.displot(df, x='MI', hue='Estimator', kde=True, height=7)\nplt.title(\"Information shared between two continuous variables\")\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}