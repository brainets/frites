{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Generate spatio-temporal ground-truths\n\nFrites provides some functions to generate spatio-temporal ground-truths (i.e.\neffects that are distributed across time and space with a predefined profile).\nThose ground-truths can be particularly interesting to simulate the data coming\nfrom multiple subjects, compare group-level strategies such as methods for\nmultiple comparisons.\n\nThis example illustrates :\n\n    * How the predefined ground-truth effects looks like\n    * How to generate the data coming from multiple subjects\n    * How to use the workflow of mutual-information to retrieve the effect\n    * How to use statistical measures to compare the effect detected as\n      significant and the ground-truth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport xarray as xr\n\nfrom frites.simulations import sim_ground_truth\nfrom frites.dataset import DatasetEphy\nfrom frites.workflow import WfMi\nfrom frites import set_mpl_style\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nset_mpl_style()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of the implemented ground truth\n\nIn this first part we illustrate the implemented ground-truths profiles. This\nincludes effects with varying covariance over time and space, weak and\ndiffuse effects and strong and focal effect.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gtypes = ['tri', 'tri_r', 'diffuse', 'focal']\nn_subjects = 1\nn_epochs = 5\n\ngts = {}\nfor gtype in gtypes:\n    gts[gtype] = sim_ground_truth(n_subjects, n_epochs, gtype=gtype,\n                                  gt_only=True, gt_as_cov=True)\n\n# plot the four ground-truths\nfig, axs = plt.subplots(\n    ncols=len(gtypes), sharex=False, sharey=False, figsize=(18, 4.5),\n    gridspec_kw=dict(wspace=.2, left=0.05, right=0.95)\n)\naxs = np.ravel(axs)\n\nfor n_g, g in enumerate(gtypes):\n    plt.sca(axs[n_g])\n    df = gts[g].to_pandas().T\n    plt.pcolormesh(df.columns, df.index, df.values, cmap='Spectral_r',\n                   shading='nearest', vmin=0., vmax=0.3)\n    plt.title(g.capitalize(), fontweight='bold', fontsize=15)\n    plt.grid(True)\n    plt.xlabel('Time (bin)')\n    if n_g == 0: plt.ylabel('Spatial (bin)')\n    plt.colorbar()\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Here, the ground-truth contains values of covariance at specific time\n      and spatial bins. The covariance reflects where there's a relation\n      between the brain data and the external continuous y variable and how\n      strong is this relation. High values of covariance indicate that the\n      brain and the continuous y variable are strongly correlated.\n      Conversely, small values of covariance indicate that the brain data and\n      the continuous y variable are weakly correlated.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data simulation\n\nIn this second part, we use the same function to simulate the data coming\nfrom multiple subjects. The returned data are a list of length n_subjects\nwhere each element of the list is an array (xarray.DataArray) of shape\n(n_epochs, n_roi, n_times). In addition to the simulated data, the external\ncontinuous variable is set as a coordinate of the trial dimension ('y')\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gtype = 'tri'    # ground truth type\nn_subjects = 10  # number of simulated subjects\nn_epochs = 100   # number of trials per subject\n\n# generate the data for all of the subjects\nda, gt = sim_ground_truth(n_subjects, n_epochs, gtype=gtype, random_state=42)\n\n# get data (min, max) for plotting\nvmin, vmax = [], []\nfor d in da:\n    d = d.mean('y')\n    vmin.append(np.percentile(d.data, 5))\n    vmax.append(np.percentile(d.data, 95))\nvmin, vmax = np.min(vmin), np.max(vmax)\n\n# plot the four ground-truths\nnrows = 2\nncols = int(np.round(n_subjects / nrows))\nwidth = int(np.round(4 * ncols))\nheight = int(np.round(4 * nrows))\n\nfig, axs = plt.subplots(\n    ncols=ncols, nrows=nrows, sharex=True, sharey=True,\n    figsize=(width, height), gridspec_kw=dict(wspace=.1, left=0.05, right=0.95)\n)\naxs = np.ravel(axs)\n\nfor n_s in range(n_subjects):\n    # subject selection and mean across trials\n    df = da[n_s].mean('y').to_pandas()\n\n    plt.sca(axs[n_s])\n    plt.pcolormesh(df.columns, df.index, df.values, cmap='Spectral_r',\n                   shading='nearest', vmin=vmin, vmax=vmax)\n    plt.title(f\"Subject #{n_s}\", fontweight='bold', fontsize=15)\n    plt.grid(True)\n    plt.xlabel('Time (bin)')\n    plt.ylabel('Spatial (bin)')\n    plt.colorbar()\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the effect size and group-level statistics\n\nIn this third part, we compute the mutual-information and the statistics at\nthe group-level using the data simulated above. To this end, we first define\na dataset containing the electrophysiological. In the simulated data, the\nspatial dimension is called 'roi', the temporal dimension is called 'times'\nand the external continuous y variable is attached along the trial dimension\nand is called 'y'. After that, we use a random-effect model for the\npopulation with p-values corrected for multiple comparisons using a cluster-\nbased approach.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# define a dataset hosting the data coming from multiple subjects\ndt = DatasetEphy(da, y='y', roi='roi', times='times')\n\n# run the statistics at the group-level\nwf = WfMi(mi_type='cc', inference='rfx')\nmi, pv = wf.fit(dt, n_perm=200, mcp='cluster')\n\n# get the t-values\ntv = wf.tvalues\n\n# xarray to dataframe conversion\ndf_tv = tv.to_pandas().T\ndf_pv = (pv < 0.05).to_pandas().T\ndf_gt = gt.astype(int).to_pandas().T\n\n# sphinx_gallery_thumbnail_number = 3\n# plot the results\nfig, axs = plt.subplots(\n    ncols=3, sharex=True, sharey=True,\n    figsize=(16, 4.5), gridspec_kw=dict(wspace=.1, left=0.05, right=0.95)\n)\naxs = np.ravel(axs)\n\nkw_title = dict(fontweight='bold', fontsize=15)\nkw_heatmap = dict(shading='nearest')\n\nplt.sca(axs[0])\nplt.pcolormesh(df_tv.columns, df_tv.index, df_tv.values, cmap='viridis',\n               vmin=0., vmax=np.percentile(df_tv.values, 99), **kw_heatmap)\nplt.colorbar()\nplt.title(f\"Effect-size at the group-level\\n(t-values)\", **kw_title)\n\nplt.sca(axs[1])\nplt.pcolormesh(df_pv.columns, df_pv.index, df_pv.values, cmap='plasma',\n               vmin=0, vmax=1, **kw_heatmap)\nplt.colorbar()\nplt.title(f\"Effects detected as significant\\nat the group-level (p<0.05)\",\n          **kw_title)\n\nplt.sca(axs[2])\nplt.pcolormesh(df_gt.columns, df_gt.index, df_gt.values, cmap='plasma',\n               vmin=0, vmax=1, **kw_heatmap)\nplt.colorbar()\nplt.title(f\"Ground-truth\\n(gtype={gtype})\", **kw_title)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison between the effect detected as significant and the ground-truth\n\nThis last section quantifies how well the statistical framework performed\non this particular ground-truth. The overall idea is to use statistical\nmeasures (namely false / true positive / negative rates) to quantify how well\nthe framework of group-level statistics is able to retrieve the ground-truth.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# bins with / without effect in the ground-truth\ntp_gt, tn_gt = (df_gt.values == 1), (df_gt.values == 0)\ndim_gt = np.prod(df_gt.values.shape)\n\nprint(\n    \"\\n\"\n    \"Ground-Truth\\n\"\n    \"------------\\n\"\n    f\"- Total number of spatio-temporal bins : {dim_gt}\\n\"\n    f\"- Number of bins with an effect : {tp_gt.sum()}\\n\"\n    f\"- Number of bins without effect : {tn_gt.sum()}\\n\"\n)\n\n# bins with / without in the retrieved effect\ntp_pv, tn_pv = (df_pv.values == 1), (df_pv.values == 0)\ndim_pv = np.prod(df_pv.values.shape)\n\nprint(\n    \"Bins detected as significant\\n\"\n    \"----------------------------\\n\"\n    f\"- Total number of spatio-temporal bins : {dim_pv}\\n\"\n    f\"- Number of bins with an effect : {tp_pv.sum()}\\n\"\n    f\"- Number of bins without effect : {tn_pv.sum()}\\n\"\n)\n\n# comparison between the ground-truth\ntp = np.logical_and(tp_pv, tp_gt).sum()\ntn = np.logical_and(tn_pv, tn_gt).sum()\nfp = np.logical_and(tp_pv, tn_gt).sum()\nfn = np.logical_and(tn_pv, tp_gt).sum()\n\nprint(\n    \"Comparison between the ground-truth and the retrieved effect\\n\"\n    \"------------------------------------------------------------\\n\"\n    f\"- Number of true positive : {tp}\\n\"\n    f\"- Number of true negative : {tn}\\n\"\n    f\"- Number of false positive : {fp}\\n\"\n    f\"- Number of false negative : {fn}\\n\"\n)\n\n# Type I error rate (false positive)\np_fp = fp / (fp + tn)  # == fp / n_false\n# Type II error rate (false negative)\np_fn = fn / (fn + tp)  # == fn / n_true\n# Sensitivity (true positive rate)\nsen = tp / (tp + fn)  # == 1. - p_fn  == tp / n_true\n# Specificity (true negative rate)\nspe = tn / (tn + fp)  # == 1. - p_fp  == tn / n_false\n# Matthews Correlation Coefficient\nnumer = np.array(tp * tn - fp * fn)\ndenom = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\nmcc = numer / denom\n\nprint(\n    f\"Statistics\\n\"\n    f\"----------\\n\"\n    f\"- Type I error (false positive rate): {p_fp}\\n\"\n    f\"- Type II error (false negative rate): {p_fn}\\n\"\n    f\"- Sensitivity (true positive rate): {sen}\\n\"\n    f\"- Specificity (true negative rate): {spe}\\n\"\n    f\"- Matthews Correlation Coefficient: {mcc}\"\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}